[
  {
    "path": "posts/2021-05-18-experimentando-o-r-410/",
    "title": "Experimentando o R 4.1.0",
    "description": "Primeiras impressões ao usar o nova versão do R",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2021-05-18",
    "categories": [
      "RStudio",
      "R",
      "Pipe"
    ],
    "contents": "\n\nContents\nIntrodução\nAtalho do pipe no RStudio\nExemplos!\nExemplo 1\nExemplo 2\nConclusão\n\n\n\n\nIntrodução\nA versão do 4.1.0 do R foi lançada hoje (dia 18 de maio de 2021), e a comunidade está bem animada com a chegada do pipe |> no R base!\nEsse post não tem como objetivo explicar quais foram as mudanças, e sim para apenas mostrar as primeiras impressões ao usar a versão 4.1.0! Caso você queira saber mais sobre as mudanças, recomendo esses textos:\nPost “R 4.1: o novo pipe está chegando!”, por Caio Lente, da Curso-R\nPost “New features in R 4.1.0”, blog da jumping rivers\nAlém disso, amanhã acontecerá uma live no canal do Youtube da Curso-R (e eu pretendo participar):\n\n\n\n\nAtalho do pipe no RStudio\nAlém de atualizar a versão do R para 4.1.0 (veja mais aqui), eu também atualizei a versão do RStudio para a preview (veja mais aqui).\nA versão preview apresenta a opção de atalho para o novo pipe, seguindo os passos: Tools > Global Options > Code > Use native pipe operator.\n\n\n\nAtivando essa opção, é possível usar o mesmo atalho de costume para escrever o pipe do R base: Ctrl + Shift + M!\nExemplos!\nPara experimentar, resolvi tentar adaptar os exemplos apresentados no capítulo sobre o operador pipe, do livro Ciência de Dados em R, da qual sou contribuidora!\n\n\n\n\n\nComo vou apresentar o código original mostrado no livro (usando o pipe do {magrittr}) e a adaptação com pipe do R base, é necessário carregar o pipe do pacote {magrittr} para que os exemplos a seguir funcionem:\n\n\n# Esse argumento include.only é útil nesse caso,\n# pois apenas a função %>% é carregada\nlibrary(magrittr, include.only = \"%>%\")\n\n\n\nO primeiro exemplo do livro mostra algumas equivalências, e adiciono então uma terceira linha, mostrando a equivalência com o pipe do R base: substituimos o %>% do {magrittr}, pelo |> do R base!\n\n\nf(x, y) # sem o pipe\nx %>% f(y) # com o pipe do magrittr\nx |> f(y) # com o pipe do R base\n\n\n\nExemplo 1\nNo primeiro exemplo, apenas foi necessário substituir o pipe do magrittr %>% pelo pipe do R base |>:\nExemplo do livro:\n\nVamos calcular a raiz quadrada da soma dos valores de 1 a 4. Primeiro, sem o pipe.\n\n\n\nx <- c(1, 2, 3, 4)\n\n\n\n\nSem pipe\n\n\n# Versão original do livro, sem usar o pipe\nsqrt(sum(x))\n\n\n[1] 3.162278\n\nPipe magrittr\n\n\n# Versão original do livro, com o pipe do magrittr\nx %>% sum() %>% sqrt()\n\n\n[1] 3.162278\n\nVersão adaptada com pipe do R base\n\n\n# Versão usando o pipe do R base\nx |> sum() |> sqrt()\n\n\n[1] 3.162278\n\n\nFoi tranquilo!\nExemplo 2\nNeste próximo exemplo, não basta fazer a substituição feita no exemplo anterior. Isso acontece porque o pipe do magrittr aceita utilizar o ponto . (chamado de dot placeholder em inglês) para indicar onde o resultado recebido pelo pipe será substituído na próxima operação. Por outro lado, o pipe do R base não aceita essa forma.\nComo o exemplo do livro utiliza o ponto ., isso teve que ser adaptado para que o código funcionasse! Essa adaptação ocorreu utilizando outra grande novidade do R 4.1.0: as funções anônimas: \\(x). Meu objetivo não é explicar aqui, mas recomendo fortemente que leia texto do Caio Lente, pois lá tem uma seção inteira sobre esse tema. Sinceramente não foi de primeira que eu acertei o uso da função anônima no exemplo abaixo, mas depois de olhar alguns outros exemplos, deu certo!\nExemplo do livro:\n\nQueremos que o dataset seja recebido pelo segundo argumento (data=) da função “lm”.\n\n\nVersão original do livro\n\n\n# Versão original do livro usando o pipe do magrittr\nairquality %>%\n  na.omit() %>%\n  lm(Ozone ~ Wind + Temp + Solar.R, data = .) %>%\n  summary()\n\n\n\nCall:\nlm(formula = Ozone ~ Wind + Temp + Solar.R, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-40.485 -14.219  -3.551  10.097  95.619 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -64.34208   23.05472  -2.791  0.00623 ** \nWind         -3.33359    0.65441  -5.094 1.52e-06 ***\nTemp          1.65209    0.25353   6.516 2.42e-09 ***\nSolar.R       0.05982    0.02319   2.580  0.01124 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.18 on 107 degrees of freedom\nMultiple R-squared:  0.6059,    Adjusted R-squared:  0.5948 \nF-statistic: 54.83 on 3 and 107 DF,  p-value: < 2.2e-16\n\nVersão adaptada com pipe do R base\n\n\n# Versão usando o pipe do R base + funções anônimas\nairquality |>\n  na.omit()  |>\n  {\\(x) lm(formula = Ozone ~ Wind + Temp + Solar.R, data = x)}() |>\n  summary()\n\n\n\nCall:\nlm(formula = Ozone ~ Wind + Temp + Solar.R, data = x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-40.485 -14.219  -3.551  10.097  95.619 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -64.34208   23.05472  -2.791  0.00623 ** \nWind         -3.33359    0.65441  -5.094 1.52e-06 ***\nTemp          1.65209    0.25353   6.516 2.42e-09 ***\nSolar.R       0.05982    0.02319   2.580  0.01124 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.18 on 107 degrees of freedom\nMultiple R-squared:  0.6059,    Adjusted R-squared:  0.5948 \nF-statistic: 54.83 on 3 and 107 DF,  p-value: < 2.2e-16\n\n\nConclusão\nÉ muito legal ver que a linguagem está desenvolvendo e incorporando contribuições que surgiram das demandas da comunidade! Muito empolgante testar coisas novas. Caso você também esteja animada(o), assista a live da Curso-R sobre o tema!\nLembrando que os códigos acima utilizando o pipe do R base e as notações das funções anônimas apenas funcionarão se você instalou a nova versão do R: 4.1.0!\nEssas são as informações relacionadas à plataforma que estou usando, e a versão do R:\n\n\nsessioninfo::session_info()$platform\n\n\n setting  value                                 \n version  R version 4.1.0 RC (2021-05-17 r80314)\n os       macOS Big Sur 11.2.3                  \n system   aarch64, darwin20                     \n ui       X11                                   \n language (EN)                                  \n collate  en_US.UTF-8                           \n ctype    en_US.UTF-8                           \n tz       America/Sao_Paulo                     \n date     2021-05-18                            \n\n\n\n\n",
    "preview": "https://cran.r-project.org/doc/manuals/r-devel/Rlogo.svg",
    "last_modified": "2021-05-18T18:57:09-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-29-desvendando-erros/",
    "title": "Desvendando erros: Entendendo mensagens de erro comuns em R",
    "description": "Post publicado no blog da Curso-R.",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      },
      {
        "name": "Fernando Corrêa",
        "url": {}
      }
    ],
    "date": "2021-03-29",
    "categories": [
      "R",
      "Erros"
    ],
    "contents": "\nLeia o post no blog da Curso-R: acesse aqui!\n\n\n\nfitvids('.shareagain', {players: 'iframe'});\n\n\n\n\n",
    "preview": "https://blog.curso-r.com/images/posts/banner/dog-pc.jpg",
    "last_modified": "2021-05-18T20:55:46-03:00",
    "input_file": "desvendando-erros.knit.md"
  },
  {
    "path": "posts/2021-03-07-estudando-bibliometrix/",
    "title": "Conhecendo o pacote bibliometrix",
    "description": "Primeiras impressões utilizando o pacote `{bibliometrix}`",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2021-03-07",
    "categories": [
      "Estudo",
      "Pesquisa"
    ],
    "contents": "\n\nContents\nIntrodução\nObtendo as bases de dados\nBiblioshiny\nUtilizando o bibliometrix no R\nImportar os dados\nFunções do bibliometrix para analisar os dados\n\nReproduzindo as visualizações com o pacote ggplot2\nAutoras(es) mais produtivas(os)\nProdução por ano\nPaíses mais produtivos\nPrincipais periódicos\n\nConclusão\nAgradecimentos\n\nIntrodução\nOlá! Eu costumo demorar bastante para escrever cada texto que adiciono neste blog, então consequentemente o blog demora muito para receber atualizações.\nPortanto, esse post será um pouco diferente dos posts anteriores! Será mais curtinho e simples, e não será um conteúdo completo, assim consigo postar o que é possível neste momento (e quem sabe faço os posts parte 2, 3, 4.. futuramente).\nDito isso, eu comecei a escrever este post enquanto estudava o pacote {bibliometrix}. Eu estou estudando este pacote para utilizar na minha pesquisa, e provavelmente ainda ficarei estudando por um tempo, já que o mesmo tem muitas possibilidades. Este post servirá de registro do que aprendi até agora, e talvez eu o atualize ao longo do tempo!\nO {bibliometrix} (Aria and Cuccurullo 2017, 2021) é um pacote que oferece ferramentas para realizar análises bibliométricas. Os tutoriais que o pacote oferece são muito interessantes e foi essencial utilizar o pacote com este tutorial aberto em outra aba!\nObtendo as bases de dados\nAntes de começar a usar o bibliometrix, é necessário obter as bases de dados que serão utilizadas. Neste exemplo, eu testei com dados obtidos nos repositórios Scopus e Web of Science, sendo que o acesso foi feito através do “Acesso CAFe” no Portal de Periódicos da Capes.\nPara testar o pacote (e escrever este post), realizei a busca de artigos com uma query genérica (não é a que eu utilizarei na minha pesquisa), para fins didáticos.\nA busca feita foi: trabalhos que possuíam as palavras “water governance” em seu título.\nQuerys:\nno Scopus: TITLE ( water  AND governance )\nno WOS: TÍTULO: (water governance)\n\nO WOS só permitiu exportar até 500 registros por vez. Foi necessário exportar 3 arquivos diferentes, porém isso dependerá da quantidade de resultados que teremos nas pesquisas!\n\n\nEste tutorial apresenta informações sobre como exportar os dados das plataformas.\n\nBiblioshiny\nO pacote possui um app em Shiny, que possibilita fazer as análises com o bibliometrix em uma interface point and click, sem que seja necessário escrever códigos! Essa é uma possibilidade muito legal para pessoas que querem usar a ferramenta mas não programam em R. Para usar o biblioshiny, é necessário:\nInstalar o R;\n\nInstalar o RStudio;\n\nInstalar o pacote bibiliometrix com a seguinte função:\ninstall.packages(\"bibliometrix\")\nAbrir a interface utilizando a função:\nbibliometrix::biblioshiny()\nUtilizando o bibliometrix no R\nEu achei muito legal a possibilidade de utilizar uma interface em Shiny, porém prefiro realizar as análises com R, assim tenho o código disponível para que seja reproduzido futuramente.\nPrimeiramente vamos carregar alguns pacotes utilizados:\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(bibliometrix)\n\n\n\nImportar os dados\nA próxima etapa é importar os dados. A função para importar é bibliometrix::convert2df(), sendo importante informar como argumento: o caminho até o arquivo a ser aberto, a fonte dos dados (dbsource) e o formato do arquivo.\nOs dados exportados do scopus são mais simples, pois é apenas um arquivo:\n\n\ndados_scopus <- bibliometrix::convert2df(\"dados/scopus.bib\",\n                                         dbsource = \"scopus\",\n                                         format = \"bibtex\")\n\n\n\nConverting your scopus collection into a bibliographic dataframe\n\nDone!\n\n\nGenerating affiliation field tag AU_UN from C1:  Done!\n\nPara importar os dados do Wos, utilizei os passos abaixo:\n\n\n# listar arquivos que preciso abrir:\n# todos eles começam com o padrão \"savedrecs_\"\narquivos_wos <-\n  list.files(\"dados\", pattern = \"^savedrecs_\", full.names = TRUE)\n\narquivos_wos\n\n\n[1] \"dados/savedrecs_1_500.bib\"      \"dados/savedrecs_1000_final.bib\"\n[3] \"dados/savedrecs_501_1000.bib\"  \n\n# Utilizando esse vetor de caminhos até os arquivos, \n# utilizamos a função convert2df para importá-los\n\ndados_wos <- bibliometrix::convert2df(arquivos_wos,\n                                      dbsource = \"wos\",\n                                      format = \"bibtex\")\n\n\n\nConverting your wos collection into a bibliographic dataframe\n\nDone!\n\n\nGenerating affiliation field tag AU_UN from C1:  Done!\n\nDepois de importar os dados das diferentes bases, é necesário unir todos em um única base, que será utilizada para fazer as análises. A função bibliometrix::mergeDbSources() realiza essa tarefa, e utilizando o argumento remove.duplicated = TRUE, os documentos duplicados são removidos.\n\n\ndados_brutos <-\n  bibliometrix::mergeDbSources(dados_scopus, dados_wos,\n                               remove.duplicated = TRUE) \n\n\n\n 1015 duplicated documents have been removed\n\n# Obrigada beholdersaltitante!\n\n\n\nOs dados exportados retornaram diferentes tipos de trabalhos, como editoriais, erratas, etc. Neste caso, quero apenas que ARTIGOS sejam mantidos na análise:\n\n\n# Quais tipos de trabalhos existem na base?\ndplyr::distinct(dados_brutos, DT) %>% \n  knitr::kable(row.names = FALSE)\n\n\nDT\nARTICLE\nERRATUM\nREVIEW\nCONFERENCE PAPER\nNOTE\nDATA PAPER\nEDITORIAL\nBOOK CHAPTER\nBOOK\nARTICLE IN PRESS\nSHORT SURVEY\nARTICLE; EARLY ACCESS\nPROCEEDINGS PAPER\nARTICLE; PROCEEDINGS PAPER\nEDITORIAL MATERIAL\nBOOK REVIEW\nCORRECTION\nMEETING ABSTRACT\nNEWS ITEM\n\n# Filtraremos apenas os artigos NA BASE\n\n  dados <- dados_brutos %>%\n  filter(DT == \"ARTICLE\")\n\n\n\nPronto! Agora temos a base preparada. O significado do nome das colunas pode ser conferido na documentação do pacote.\n\n\ndplyr::glimpse(dados)\n\n\nRows: 1,176\nColumns: 32\n$ AU       <chr> \"JOHNS C;VANNIJNATTEN D\", \"SAN J M C;ARMARIO B J\", …\n$ DE       <chr> \"ADAPTIVE GOVERNANCE;  COMPLEXITY THEORY;  ENVIRONM…\n$ ID       <chr> NA, NA, \"DECISION MAKING;  WATER MANAGEMENT;  WATER…\n$ C1       <chr> \"RYERSON UNIVERSITY, CANADA; WILFRID LAURIER UNIVER…\n$ CR       <chr> \"AKAMANI, K., ADAPTIVE WATER GOVERNANCE: INTEGRATIN…\n$ JI       <chr> \"ENVIRON. SUSTAIN. IND.\", \"J. ARID ENVIRON.\", \"J. C…\n$ AB       <chr> \"FOR THE PAST FEW DECADES, JURISDICTIONS HAVE BEEN …\n$ PA       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ AR       <chr> \"100102\", \"104403\", \"125804\", \"143867\", NA, NA, NA,…\n$ RP       <chr> \"JOHNS, C.; RYERSON UNIVERSITYCANADA; EMAIL: CJOHNS…\n$ DT       <chr> \"ARTICLE\", \"ARTICLE\", \"ARTICLE\", \"ARTICLE\", \"ARTICL…\n$ DI       <chr> \"10.1016/j.indic.2021.100102\", \"10.1016/j.jaridenv.…\n$ BE       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FU       <chr> \"SOCIAL SCIENCES AND HUMANITIES RESEARCH COUNCIL OF…\n$ BN       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ SN       <chr> \"26659727\", \"01401963\", \"09596526\", \"00489697\", \"10…\n$ SO       <chr> \"ENVIRONMENTAL AND SUSTAINABILITY INDICATORS\", \"JOU…\n$ LA       <chr> \"ENGLISH\", \"ENGLISH\", \"ENGLISH\", \"ENGLISH\", \"ENGLIS…\n$ TC       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, …\n$ PN       <chr> NA, NA, NA, NA, \"1\", \"2\", \"1\", \"1\", NA, NA, \"2\", NA…\n$ PP       <chr> NA, NA, NA, NA, \"111-129\", \"434-444\", \"1-35\", \"177-…\n$ PU       <chr> \"ELSEVIER B.V.\", \"ACADEMIC PRESS\", \"ELSEVIER LTD\", …\n$ DB       <chr> \"ISI\", \"ISI\", \"ISI\", \"ISI\", \"ISI\", \"ISI\", \"ISI\", \"I…\n$ TI       <chr> \"USING INDICATORS TO ASSESS TRANSBOUNDARY WATER GOV…\n$ VL       <chr> \"10\", \"187\", \"290\", \"761\", \"32\", \"17\", \"23\", \"70\", …\n$ PY       <dbl> 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 202…\n$ FX       <chr> \"THIS RESEARCH WAS FUNDED BY THE SOCIAL SCIENCES AN…\n$ AU_UN    <chr> \"RYERSON UNIVERSITY;WILFRID LAURIER UNIVERSITY\", \"U…\n$ AU1_UN   <chr> \"NOTREPORTED;RYERSON UNIVERSITYCANADA;NOTREPORTED\",…\n$ AU_UN_NR <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ SR_FULL  <chr> \"JOHNS C, 2021, ENVIRON SUSTAIN IND\", \"SAN JUAN MES…\n$ SR       <chr> \"JOHNS C, 2021, ENVIRON SUSTAIN IND\", \"SAN JUAN MES…\n\nFunções do bibliometrix para analisar os dados\nO pacote bibliometrix possui uma função chamada bibliometrix::biblioAnalysis(), que fornece uma sumarização dos dados. Não vou apresentar o resultado aqui pois é muito longo e não agrega muito no post, mas é possível ver um exemplo neste tutorial do pacote.\n\n\nresumo <- bibliometrix::biblioAnalysis(dados)\n\n\n\nAlgo interessante são os gráficos gerados pela função plot() quando oferecemos o resultado da função bibliometrix::biblioAnalysis(). São gerados diversos gráficos padronizados automaticamente:\n\n\ngraficos_bibliometrix <- plot(resumo)\n\n\n\n\nPorém os gráficos são gerados em inglês, e não consegui personalizar os gráficos já gerados. Portanto, acho que um exercício legal é reproduzir as visualizações para que seja possível personalizar o que for necessário (por exemplo, o idioma), e gerar as imagens formatadas para adicionar nos nossos relatórios.\nReproduzindo as visualizações com o pacote ggplot2\nAutoras(es) mais produtivas(os)\nFazendo com bibliometrix\n\n\ngraficos_bibliometrix[1]\n\n\n$MostProdAuthors\n\n\nReproduzindo com ggplot2\n\n\n# Primeiro precisamos descobrir qual é o \n# número máximo de autores em um artigo.\n# Isso será usado depois para separar a coluna\n# de nomes de pessoas autoras.\nnumero_max_autores <-\n  stringr::str_split(dados$AU, \";\") %>% \n  lengths() %>%\n  max()\n\n\n\ndados %>%\n  tidyr::separate(AU,\n                  sep = \";\",\n                  into = glue::glue(\"autor_{1:numero_max_autores}\")) %>%\n  tidyr::pivot_longer(\n    cols = glue::glue(\"autor_{1:10}\"),\n    names_to = \"ordem_autor\",\n    values_to = \"nome_autor\",\n    values_drop_na = TRUE\n    \n  ) %>%\n  dplyr::group_by(nome_autor) %>%\n  dplyr::count() %>%\n  dplyr::arrange(desc(n)) %>%\n  dplyr::ungroup() %>%\n  dplyr::slice(1:10) %>%\n  ggplot() +\n  geom_col(aes(x = reorder(nome_autor,\n                           desc(n)), y = n), \n           fill = '#4b689c') +\n  coord_flip() +\n  theme_bw() +\n  labs(x = \"Pessoas autoras\", \n       y = \"Quantidade de artigos\")\n\n\n\n\nProdução por ano\nFazendo com bibliometrix\n\n\ngraficos_bibliometrix[3]\n\n\n$AnnualScientProd\n\n\nReproduzindo com ggplot2\n\n\n# O código abaixo é necessário para preencher \n# com 0 os anos sem nenhuma publicação.\nanos_vazios <- tibble::tibble(\n  PY = min(dados$PY):max(dados$PY), \n  n = 0\n) %>% \n  dplyr::filter(!PY %in% unique(dados$PY))\n\n\ndados %>%\n  dplyr::count(PY) %>% \n  dplyr::full_join(anos_vazios) %>% \n  dplyr::arrange(PY) %>% \n  ggplot(aes(x = PY, y = n)) +\n  geom_line() +\n  geom_area(fill = '#002F80', alpha = .5) +\n  theme_bw() +\n  labs(x = \"Ano\", y = \"Quantidade de artigos\")\n\n\n\n\nPaíses mais produtivos\nFazendo com bibliometrix\n\n\ngraficos_bibliometrix[2]\n\n\n$MostProdCountries\n\n\nReproduzindo com ggplot2\n\n\n# Não consegui reproduzir os dados pois não encontrei\n# a informação de países na base inicial.\n# Julio Trecenti deu uma dica sobre como obter\n# os dados a partir de um objeto ggplot.\npaises_mais_produtivos <- graficos_bibliometrix[[2]][[\"data\"]]\ndplyr::glimpse(paises_mais_produtivos)\n\n\nRows: 20\nColumns: 3\n$ Country       <fct> USA, GERMANY, UNITED KINGDOM, NETHERLANDS, AUS…\n$ Freq          <dbl> 4, 4, 0, 2, 0, 2, 4, 2, 3, 2, 111, 83, 81, 76,…\n$ Collaboration <chr> \"MCP\", \"MCP\", \"MCP\", \"MCP\", \"MCP\", \"MCP\", \"MCP…\n\npaises_mais_produtivos %>% \n  ggplot() + \n  geom_col(aes(x = Country,\n               y = Freq, fill = Collaboration)) +\n  coord_flip() +\n  theme_bw() +\n  labs(x = \"Países\",\n       y = \"Quantidade de artigos\",\n       fill = \"Colaboração\", \n       caption = \"\\n \\n MCP: Publicação com pessoas autoras de mais de um país. \\n\n       SCP: Publicação com pessoas autoras de apenas um país.\")\n\n\n\n\nPrincipais periódicos\nFazendo com bibliometrix\n\n\n# Não encontrei a função. Mas tem essa opcão no biblioshiny.\n# Pesquisar mais!\n\n\n\nFazendo com ggplot2\n\n\ndados %>%\n  dplyr::mutate(SO = gsub('(.{1,30})(\\\\s|$)', \n                          '\\\\1\\n', SO )\n    ) %>%\n      dplyr::count(SO) %>%\n      dplyr::arrange(desc(n)) %>% \n      dplyr::slice(1:10) %>% \n      ggplot() +\n      geom_col(aes(x = reorder(SO, n),\n                   y = n),\n               fill = \"#4b689c\") +\n      coord_flip() +\n      theme_bw() +\n      labs(x = \"Periódico\", \n           y = \"Quantidade de artigos\")\n\n\n\n\nConclusão\nEste texto é um trabalho em andamento! Mas até agora percebi que o bibliometrix oferece ferramentas muito interessantes, principalmente para importar as bases de dados de diferentes fontes.\nPretendo continuar estudando como utilizar este pacote, pois existem muitas possibilidades ainda a serem exploradas.\nAgradecimentos\nWalmes Zeviani por disponibilizar o vídeo do treinamento oferecido pelo LEG UFPR e ministrado pela Angélica Tortola Ribeiro (UTFPR e PPGMNE), sobre análise de referências bibliográficas com apoio do pacote Bibliometrix.\nEu comecei a fazer estes estudos (e escrever este post) durante uma transmissão no meu canal na Twitch. Foi muito legal e algumas pessoas participantes me deram dicas sobre o pacote e me ajudaram neste percurso! Obrigada para quem participou e para quem deu dicas!\nEdit: Agradeço ao Julio Trecenti pela dica de como obter os dados utilizados para criar um ggplot.\n\n\n\n\n\n\nAria, Massimo, and Corrado Cuccurullo. 2017. “Bibliometrix: An r-Tool for Comprehensive Science Mapping Analysis.” Journal of Informetrics 11 (4): 959–75. https://doi.org/10.1016/j.joi.2017.08.007.\n\n\n———. 2021. Bibliometrix: Comprehensive Science Mapping Analysis. https://CRAN.R-project.org/package=bibliometrix.\n\n\n\n\n",
    "preview": "posts/2021-03-07-estudando-bibliometrix/estudando-bibliometrix_files/figure-html5/unnamed-chunk-12-1.png",
    "last_modified": "2021-05-11T17:01:36-03:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-03-02-certificacao-rstudio/",
    "title": "Certificação da RStudio",
    "description": "Este post relata como foi o processo pra mim de realizar a certificação da RStudio: RStudio Instructor Training and Certification.",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2021-03-02",
    "categories": [
      "RStudio",
      "Comunidades",
      "Portugues",
      "Ensino"
    ],
    "contents": "\n\nContents\nImportância da comunidade\nComo iniciar o processo de treinamento?\nTreinamento\nProvas de certificação\nProva de Ensino\nProva sobre tidyverse\n\nAprovação!\nE o Inglês?\nConclusão\nAgradecimentos 💜\nMais materiais úteis\nTwitch\n\nAno passado, eu realizei o processo de treinamento e certificação da RStudio, e este post tem com objetivo relatar como foi este processo para mim, afim de possivelmente oferecer informações e ajudar outras pessoas interessadas em realizar essa certificação.\nA RStudio oferece a possibilidade de realizar a certificação de treinamento sobre os pacotes tidyverse e shiny. Todas as informações necessárias sobre a certificação estão disponíveis neste site, porém também adicionarei alguns links extras aqui!\n\nImportante: Eu realizei o processo completo de treinamento com o Greg Wilson, porém ele não está mais envolvido no processo de certificação. Portanto, não sei se alguma etapa será alterada. Aqui descreverei como o processo foi quando eu realizei o treinamento.\n\nImportância da comunidade\nPrimeiro de tudo: eu gostaria de destacar que a comunidade de R foi essencial para que eu pudesse realizar o treinamento e receber a certificação.\nQuando eu fiquei sabendo da existência dessa certificação, eu logo me deparei com uma dificuldade para participar: no site dizia que era necessário pagar (em dólares) para realizar o processo. Para quem é Brasileiro, sabemos como a moeda local é muito desvalorizada, e isso acaba dificultando a participação de muitas pessoas.Então eu deixei pra lá, até que vi um post no blog da Yanina Saibene falando como foi o processo de certificação para ela. Então entrei em contato com ela (que havia conhecido pessoalmente na LatinR 2019) para saber mais sobre como foi o processo para ela.\nEla me colocou em contato com um grupo de pessoas que fazem parte de diversos capítulos da R-Ladies na América Latina, que estavam se organizando para começar um grupo de estudos (e apoio!) para realizar o processo. Além disso, também me deu mais informações sobre como fazer o processo de forma mais acessível financeiramente.\nPara esse grupo de estudos, foi criado um canal no Slack, onde eram compartilhadas dicas, resoluções de exercícios e dúvidas, entre outros. Além disso, nos encontravamos semanalmente via zoom para discutir os capítulos do livro R for Data Science (também disponível em Espanhol neste link).\nA orientação da Yanina Saibene e os estudos em grupo foram essenciais para que eu me preparasse para as provas, e me sentisse confiante em realizá-las.\nComo iniciar o processo de treinamento?\nSe você se interessou em realizar o processo de treinamento, o primeiro passo para começar é ler as instruções que estão disponíveis nesta página, e preencher este formulário.\n\nAo preencher o formulário, responda com atenção as duas perguntas opcionais a final do mesmo:\nA primeira é sobre o pertencimento a grupos sub-representados em ciência de dados; neste caso, descreva bem quais são os grupos que você faz parte, e aponte as suas contribuições para a comunidade de R.\nA segunda é sobre a possibilidade de redução da taxa de aplicação das provas e treinamento (fee waiver) para pessoas de países em desenvolvimento (lower-income countries).\n\nTreinamento\nApós receber uma mensagem de aceite, é necessário indicar uma dentre as datas possíveis para realizar o treinamento. O treinamento que eu fiz foi realizado no período de duas manhãs, online (através da ferramenta Zoom), e foi em Inglês. O foco do treinamento não foi sobre programação em R, e sim sobre ensino e didática! Todo o conteúdo dos slides utilizados estão disponíveis neste link.\nMuito do conteúdo apresentado foi parecido com o treinamento oferecido pela The Carpentries (que eu descrevi neste post), e também com o conteúdo do livro escrito por Greg Wilson, entitulado Teach Tech Together:\nProvas de certificação\nApós realizar o treinamento, a próxima etapa foi realizar a prova de ensino, e a prova da certificação desejada (que, no meu caso, foi sobre tidyverse). Neste link é possível acessar um exemplo de provas, disponiblizado pela RStudio para estudo.\nNão existe ordem correta para realizar as provas! Outro ponto importante é que as provas foram feitas com a tela compartilhada, e foi permitido fazer qualquer tipo de pesquisa na internet. Porém a prova tem um limite de tempo, então é importante ficar atenta(o) ao tempo que usa pesquisando!\nProva de Ensino\nA prova de ensino foi composta por uma aula demonstrativa de 15 minutos, e algumas questões a serem respondidas (relacionadas à ensino).\nAntes da prova em si, foi necessário enviar alguns materiais solicitados para serem utilizados em uma aula demonstrativa. Os materiais que eu preparei estão disponibilizados nesta página: https://beatrizmilz.github.io/RStudio_Certification/ (e o código também está disponível neste repositório no GitHub.\nEu utilizei ferramentas como uma página onde o material é disponibilizado feita com o pacote distill (Allaire et al. 2021), a apresentação feita com o pacote xaringan (Xie 2021), dois exercícios para serem feitos ao final da aula utilizando o pacote learnr (Schloerke et al. 2021), a demonstração com código ao vivo foi realizada usando a IDE RStudio, e um mapa conceitual elaborado com a ferramenta CMap Tools. Porém essas são as ferramentas que eu escolhi utilizar, e eu recomendo que você utilize o que estiver mais confortável para você! A única ferramenta que é obrigatória a ser utilizada nessa etapa é a IDE RStudio (o que é fácil de entender o motivo…).\nProva sobre tidyverse\nA prova de tidyverse consistiu em resolver diversos exercícios usando R e tidyverse. A recomendação da RStudio para estudar para essa prova é a leitura do livro R for Data Science.\nNão tenho muito a falar desta etapa, apenas que pratique e use o quanto possível no seu dia-a-dia, assim você terá mais experiência e conseguirá resolver os problemas mais rapidamente durante a prova.\n\nQuero ainda escrever um post sobre algumas funções que não são tão comuns, mas que foram úteis para a prova! Assim que o post estiver disponível, editarei e adicionarei o link aqui.\n\nAprovação!\nApós a aprovação nas provas, recebi um email com um certificado, e também solicitaram o envio de algumas informações para que a página com minhas informações fosse adicionada na lista de pessoas treinadoras certificadas. A página contendo minhas informações pode ser acessada através deste link, e o certificado recebido foi esse:\n\n\n\nFigure 1: Certificado recebido após completar o ‘Tidyverse Instructor Certification.’\n\n\n\nAlém disso, também fui convidada para participar de um canal do Slack da RStudio, onde outras pessoas certificadas conversam sobre temas relacionados à certificação, como ensino, didática, R, tidyverse, shiny, entre outros.\nE também não poderia faltar a comemoração, né? Devido à pandemia, o encontro com as pessoas amigas foi online. Também teve um tweet de agradecimento:\n\n\n\n\n\nVeja a thread completa neste link!\nE o Inglês?\nNa minha percepção, é importante ter alguma experiência com Inglês, pois o treinamento de 2 manhãs é realizado ao vivo, totalmente no idioma. Não sei se a RStudio tem planos de aplicar o treinamento em outros idiomas (como a The Carpentries, onde já existe alguns oferecimentos de treinamentos em Espanhol).\nAs provas que eu realizei foram aplicadas pelo Greg Wilson e acompanhadas pelo brasileiro Daniel Falbel (que trabalha na RStudio no desenvolvimento do Torch for R, e também é um dos sócios fundadores da Curso-R). A participação do Daniel possibilitou que eu realizasse a apresentação da prova didática totalmente em Português, além de poder responder as perguntas da prova em Português também. Quero deixar registrado aqui o meu agradecimento para o Greg Wilson por apresentar essa possibilidade, e também ao Daniel Falbel por aceitar acompanhar esse processo! Foi muito importante para me sentir mais tranquila na prova, já que teria que me preocupar menos com o idioma e mais com o conteúdo das provas em si.\nConclusão\nPara mim, realizar este processo foi uma experiência rica onde aprendi e refleti sobre conteúdos importantes para que eu possa compartilhar cada vez mais conteúdo sobre R com qualidade. Dito isso, eu desejo fortemente que mais pessoas da comunidade Latino Americana façam o processo de treinamento.\nCaso eu não tenha abordado algum tema, ou você tenha dúvidas ao ler o post, peço que entre em contato comigo! Pode ser comentando neste post, ou enviando uma mensagem no twitter.\nAgradecimentos 💜\nEu já deixei diversos agradecimentos ao longo do texto, porém quero deixar em destaque a minha gratidão para pessoas que foram fundamentais para este processo:\nEquipe da RStudio, Greg Wilson e Daniel Falbel: obrigada por possibilitar a realização deste treinamento!\nYanina Saibene, por toda a disposição de me mostrar os caminhos a seguir!\nNão foi fácil manter a motivação de estudos durante a pandemia, porém estudar em grupo ajudou muito a continuar. Então, para as pessoas que estudaram comigo, agradeço muito os momentos de estudo, troca, apoio, e ajuda com o Espanhol também.\nRiva Quiroga\nGabriela Sandoval\nSteph Orellana Bello\nSilvy Salinas\nLucia Rodriguez-Planes\nRoxana Noelia\nPatricia Loto\nAna Laura Diedrichs\nJuliana Benitez\nJaviera Riffo Torres\n\nMinha amiga querida Angélica Custódio, por todo o apoio e por acreditar em mim (mesmo quando eu estava com medo de não conseguir você estava lá pra me animar a continuar a estudar 💜).\nAs pessoas das comunidades que eu participo e aprendi tanto até aqui: R-Ladies São Paulo, Curso-R, Latin-R.\nMais materiais úteis\nPosts em blogs de pessoas que fizeram a certificação:\nYanina Bellini Saibene\nSilvia Canelón - Recomendo muito a leitura, apresenta uma grande lista de links úteis também!\nShel Kariuki\nTed Laderas\n\nThe Carpentries Instructor Training: Suggested Rubric for Teaching Demonstrations - Essa página da The Carpentries apresenta alguns exemplos de pontos a serem observados para o feedback em aulas, com exemplos positivos e negativos sobre conteúdo e apresentação. É muito legal treinar o oferecimento da aula teste e tentar fazer uma reflexão e auto-feedback, utilizando esses pontos como partida!\nArtigos sugeridos pelo Greg Wilson:\nTen quick tips for creating an effective lesson\nTen quick tips for delivering programming lessons\n\nTwitch\nEu escrevi este post durante uma transmissão na Twitch. Obrigada a todas as pessoas que participaram! Caso queira acompanhar transmissões de conteúdo de uso de R, principalmente fazendo tarefas do dia-a-dia usando RMarkdown, basta seguir o canal twitch.tv/beamilz!\n\n\n\n\n\n\nAllaire, JJ, Rich Iannone, Alison Presmanes Hill, and Yihui Xie. 2021. Distill: R Markdown Format for Scientific and Technical Writing.\n\n\nSchloerke, Barret, JJ Allaire, Barbara Borges, and Garrick Aden-Buie. 2021. Learnr: Interactive Tutorials for r.\n\n\nXie, Yihui. 2021. Xaringan: Presentation Ninja. https://github.com/yihui/xaringan.\n\n\n\n\n",
    "preview": "https://beatrizmilz.com/img/certificado-rstudio.jpg",
    "last_modified": "2021-03-07T14:09:18-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-07-27-criando-mapas-com-os-pacotes-tidyverse-e-geobr/",
    "title": "Criando mapas com os pacotes tidyverse e geobr",
    "description": "Utilizando dados sobre coleta e tratamento de esgoto no Estado De São Paulo",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2020-07-27",
    "categories": [
      "Portugues",
      "Reprodutibilidade"
    ],
    "contents": "\n\nContents\nDados utilizados\nPacotes necessários\nAbrir e arrumar as bases brutas\nDados de Saneamento\nDados shapefile dos município\nLista de UGRHIS\n\nUnir as bases !\nVisualizando os dados\nConclusão do post\nRecomendações para a base da CETESB\nInformações sobre a sessão do R e RStudio\nMuito obrigada!\n\nComo eu estou meses sem postar nada no blog, resolvi postar um código adaptado, referente a um projeto final que realizei para a disciplina “FLS6397 - Introdução à Análise de Dados, Programação e Visualização para as Ciências Sociais”. A disciplina ocorreu no primeiro semestre de 2020, na FFLCH/USP (porém devido à pandemia, a maior parte das aulas foi online). Na página da disciplina, está disponível tutoriais com todo o conteúdo da disciplina, de graça e aberto para todes!\nAs instruções para a realização do projeto estão disponíveis na página da disciplina.\nDados utilizados\nDados de Saneamento:  A Companhia Ambiental do Estado de São Paulo (CETESB)1 publica todos os anos o “Relatório de Qualidade das Águas Interiores do Estado de São Paulo.” Desde o relatório referente ao ano de 2016, é publicado o Apêndice C, que contém dados de saneamento por município do Estado de São Paulo. Os arquivos são disponibilizados em arquivo PDF, e especificamente para o ano de 2016 é um arquivo PDF que não possibilita copiar as informações (como uma imagem, por exemplo). O relatório mais recente é referente ao ano de 2018.\nDados shapefile dos municípios: Foi utilizado o pacote {geobr} (Pereira and Goncalves 2021), que possibilita acessar dados espaciais oficiais do Brasil.\nNeste post, irei focar em mostrar como abri os dados, e utilizando principalmente o tidyverse (Wickham et al. 2019) e o pacote geobr (Pereira and Goncalves 2021), criei mapas com esses dados.\nPacotes necessários\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(geobr)\n# install.packages(\"pdftables\")\nlibrary(pdftables)\nlibrary(readr)\nlibrary(stringr)\nlibrary(abjutils)\nlibrary(ggspatial)\nlibrary(tibble)\nlibrary(knitr)\nlibrary(sf)\n\n\n\n\nO que é :: ?\nNos códigos abaixo, muitas vezes me refiro à uma função utilizando o formato pacote::funcao(), sendo que o que vem antes dos :: é o nome do pacote em qual à função pertence, e depois dos :: é o nome da função que quero usar.\nIsso é útil pois:\nCaso o pacote não esteja carregado com a função library(pacote), ainda sim o R entenderá qual função você está se referindo, e executará o código.\nCaso você se refira à uma função apenas pelo nome (sem considerar o ::), em uma situação onde você carregou pacotes diferentes que possuem funções com nome igual, a função do pacote carregado por último será utilizada. Isso pode causar a execução de uma função indesejada. Portanto, utilizar o :: ajuda a garantir a utilização da função desejada.\n\nAbrir e arrumar as bases brutas\nDados de Saneamento\nO primeiro passo é fazer o download do arquivo PDF referente ao Apêndice C e converter em CSV. A função download.file() possibilita fazer download de arquivos diretamente do R.\n\n\n# Link do relatório\nurl <-\n  \"https://cetesb.sp.gov.br/aguas-interiores/wp-content/uploads/sites/12/2019/10/Ap%C3%AAndice-C_Dados-de-Saneamento-por-Munic%C3%ADpio.pdf\" \n\n\n#Fazer o download do arquivo PDF\n\ndownload.file(url, # URL do arquivo a ser baixado\n              destfile = \"dados/apendice_c_2018.pdf\", # Informar onde quer que seja salvo, e com qual nome e extensão \n              method = \"curl\" # Método utilizado para o download\n              )\n\n\n\nPara fazer a conversão, utilizei o pacote {pdftables} (Persson 2016), que possibilita converter o arquivo PDF para CSV diretamente do R, através da API (e omiti a minha chave da API no código):\n\nO que é API?\nÉ a sigla para “Application Programming Interfaces,” ou em português, “Interface de programação de aplicações.”\nNeste exemplo, caso não fosse utilizar a API, seria necessário realizar o upload do arquivo PDF no site PDFTables, e depois baixar o arquivo convertido.\nPara utilizar a API, é necessário fazer um cadastro no site, e na aba API é disponibilizado a chave da API para utilizá-la. Posteriormente, pode-se utilizar a função pdftables::convert_pdf() para fazer a conversão diretamente do R. Isso é muito útil quando temos uma grande quantidade de arquivos, e também para deixar registrado a etapa realizada.\nCaso queira saber mais sobre APIs, leia essa página do material da Curso-R.\n\n\n\n# Converter o arquivo PDF em CSV. Utilizei a API que obtive no site, mas para compilar, omiti a API key.\n\npdftables::convert_pdf(\"dados/apendice_c_2018.pdf\",\n                       # Arquivo para converter\n                       output_file = \"dados/apendice_c_2018.csv\",\n                       #  Informar onde quer o arquivo gerado\n                       # seja salvo, e com qual nome e extensão\n                       api_key = \"...\" # Chave da API, gerada através do site.\n                       )\n\n\n\nA tabela convertida em .csv pode ser acessada neste link. O próximo passo é carregar a base, usando a função readr::read_csv():\n\n\napendice_c_2018 <-\n  readr::read_csv(\n    \"dados/apendice_c_2018.csv\", # Qual arquivo CSV quero carregar\n    col_names = c(\n      # define o nome das colunas\n      \"ugrhi\",\n      \"municipio\",\n      \"consessao\",\n      \"pop_urbana\",\n      \"atendimento_coleta_porc\",\n      \"atendimento_tratamento_porc\",\n      \"eficiencia\",\n      \"carga_poluidora_potencial\",\n      \"carga_poluidora_remancescente\",\n      \"ictem\",\n      \"corpo_receptor\"\n    ),\n    locale = readr::locale(encoding = \"ISO-8859-1\"),\n    # encoding dos dados\n    skip = 5 # Quantas linhas para pular no CSV antes de começar a ler os dados.\n  )\n\n\n\n\nEncoding?\nUma das informações importantes que utilizei na função para ler os dados no R, no código acima, é o Encoding. O Encoding está relacionado à codificação dos caracteres. Você já carregou uma base de dados onde os caracteres apareceram desconfigurados, como na imagem abaixo? Provavelmente era um erro de Encoding!\n\n\n\nAo carregar um arquivo, é util saber em qual encoding ele foi salvo.\nO recomendado ao salvar um arquivo é utilizar o encoding UTF-8.2\n\nA base deve conter 645 linhas, referente ao número de municípios no estado de São Paulo3:\n\n\nnrow(apendice_c_2018) # consulta quantas linhas tem na base\n\n\n[1] 701\n\nA base contém mais linhas do que municípios. O código abaixo retira linhas que apenas contém NA, e linhas que não apresentam dados dos municípios:\n\n\napendice_c_filtrado <- apendice_c_2018 %>%\n  # Filtrar linhas que não contém nome de municípios\n  dplyr::filter(!municipio %in% c(\"Estado de São Paulo\", \"Município\", NA, \"MUNICÍPIO\")) \n\n\n\nAgora a base tem 645 linhas, o que corresponde aos 645 municípios do estado de SP. É importante também verificar o tipo de dados nas colunas:\n\n\ntibble::glimpse(apendice_c_filtrado)\n\n\nRows: 645\nColumns: 11\n$ ugrhi                         <chr> \"1\", \"1\", \"1\", \"2\", \"2\", \"2\", …\n$ municipio                     <chr> \"Campos do Jordão\", \"Santo Ant…\n$ consessao                     <chr> \"SABESP\", \"SABESP\", \"SABESP\", …\n$ pop_urbana                    <chr> \"51440\", \"4033\", \"5224\", \"3560…\n$ atendimento_coleta_porc       <chr> \"52\", \"47\", \"92\", \"70\", \"91\", …\n$ atendimento_tratamento_porc   <chr> \"100\", \"100\", \"75\", \"28\", \"100…\n$ eficiencia                    <chr> \"97\", \"80\", \"76\", \"70\", \"82\", …\n$ carga_poluidora_potencial     <chr> \"2.778\", \"218\", \"282\", \"1.923\"…\n$ carga_poluidora_remancescente <chr> \"1.377\", \"136\", \"133\", \"1.659\"…\n$ ictem                         <chr> \"6,06\", \"4,65\", \"6,14\", \"2,56\"…\n$ corpo_receptor                <chr> \"Rio Capivari, Rio Sapucaí-Gua…\n\nAlgumas colunas são de dados numéricos mas que foram carregadas como texto (<chr>), portanto devem ser convertidas para o tipo correto (possível com a função dplyr::mutate():\n\n\napendice_c <- apendice_c_filtrado %>%\n  dplyr::mutate(\n    pop_urbana = as.double(pop_urbana) , \n    atendimento_coleta_porc = as.double(atendimento_coleta_porc),\n    atendimento_tratamento_porc = as.double(atendimento_tratamento_porc),\n    eficiencia = as.double(eficiencia),\n    \n    # As conversões abaixo tem uma etapa a mais, devido à padronização diferente utilizada na base, \n    #com o ponto e a vírgula para representar as casas decimais:\n    carga_poluidora_potencial =  stringr::str_replace_all(carga_poluidora_potencial, \"\\\\.\", \"\") %>%\n      as.double(),\n    \n    carga_poluidora_remancescente =  stringr::str_replace_all(carga_poluidora_remancescente, \"\\\\.\", \"\") %>%\n      as.double(),\n    ictem =  stringr::str_replace_all(ictem, \",\", \"\\\\.\") %>% as.double()\n    \n  )\n\n\n\nAgora podemos observar novamente o tipo de dados nas colunas, e verificar se todos os dados estão no formato ideal para a análise:\n\n\ntibble::glimpse(apendice_c)\n\n\nRows: 645\nColumns: 11\n$ ugrhi                         <chr> \"1\", \"1\", \"1\", \"2\", \"2\", \"2\", …\n$ municipio                     <chr> \"Campos do Jordão\", \"Santo Ant…\n$ consessao                     <chr> \"SABESP\", \"SABESP\", \"SABESP\", …\n$ pop_urbana                    <dbl> 51440, 4033, 5224, 35604, 1863…\n$ atendimento_coleta_porc       <dbl> 52, 47, 92, 70, 91, 100, 89, 1…\n$ atendimento_tratamento_porc   <dbl> 100, 100, 75, 28, 100, 0, 100,…\n$ eficiencia                    <dbl> 97, 80, 76, 70, 82, NA, 62, 75…\n$ carga_poluidora_potencial     <dbl> 2778, 218, 282, 1923, 101, 140…\n$ carga_poluidora_remancescente <dbl> 1377, 136, 133, 1659, 26, 140,…\n$ ictem                         <dbl> 6.06, 4.65, 6.14, 2.56, 8.22, …\n$ corpo_receptor                <chr> \"Rio Capivari, Rio Sapucaí-Gua…\n\nAgora a base está pronta para uso!\nDados shapefile dos município\nOs dados foram obtidos com o pacote geobr:\n\n\n# Lê a base de dados espaciais (do tipo Shapefile) dos municípios do Estado de São Paulo,\n# no ano de 2018, segundo o IBGE.\n# Os dados salvos são da classe Simple Feature\n\nmunicipios_sp <- geobr::read_municipality(\"SP\", 2018)\n\n\n\n\nO pacote geobr (Pereira and Goncalves 2021) é um pacote que disponibiliza funções para realizar o download de diversas bases de dados espaciais oficiais do Brasil. Você pode saber mais no repositório do pacote no GitHub.\nO pacote sf (Simple Features for R) (Pebesma 2021, 2018) possibilita trabalhar com essas bases de dados espaciais. Gosto muito da seguinte ilustação da Allison Horst sobre esse pacote:\n\n\n\n\nLista de UGRHIS\nNo projeto, defini como área de estudo os municípios das seguintes Unidades de Gerenciamento de Recursos Hídricos (UGRHI): Paraíba do Sul, Litoral Norte, Piracicaba/Capivari/Jundiaí, Alto Tietê, Baixada Santista e Tietê/Sorocaba. Essas UGRHIs foram escolhidas por estarem totalmente ou marjoritariamente no território da Macrometrópole Paulista (MMP) (considerando a delimitação do DAEE4).\nCriei manualmente uma tibble com o número e nome das UGRHIs que farão parte da análise:\n\n\nugrhis <- tibble::tibble(\n  ugrhi = c(\"2\",\n            \"3\",\n            \"5\",\n            \"6\",\n            \"7\",\n            \"10\"),\n  nome_ugrhi = c(\n    \" Paraíba do Sul\",\n    \" Litoral Norte\",\n    \" Piracicaba/Capivari/Jundiaí\",\n    \" Alto Tietê\",\n    \" Baixada Santista\",\n    \" Tietê/Sorocaba\"\n  )\n)\n\n\n\nUnir as bases !\nA base da CETESB não possui o código de município do IBGE (o ideal para fazer o Join). Neste caso, podemos usar o nome do município, porém é preciso padronizar os nomes em relação à maiúsculas/minúsculas, acentos, presença de traços, entre outros. A maior diferença encontrada foi na grafia do nome do município “São Luiz do Paraitinga”: segundo o site da Assembléia Legislativa do Estado de São Paulo, e o site do município, Luiz é escrito com Z, porém a base da CETESB utiliza a forma incorreta: “São Luís do Paraitinga.” Essas inconsistências foram corrigidas com código abaixo, usando principalmente funções dos pacotes stringr, dplyr e abjutils:\n\n\nmunicipios_sp_limpo <-\n  municipios_sp %>% dplyr::mutate(\n    nome_muni = stringr::str_to_lower(name_muni),\n    nome_muni = stringr::str_replace_all(nome_muni, \"-\", \" \"),\n    nome_muni = abjutils::rm_accent(nome_muni)\n  )\n\napendice_c_limpo <- apendice_c %>% dplyr::mutate(\n  nome_muni =  dplyr::case_when(\n    municipio == \"São Luís do Paraitinga\" ~\n      \"São Luiz do Paraitinga\",\n    TRUE ~ municipio\n  ),\n  nome_muni = stringr::str_to_lower(nome_muni),\n  nome_muni = stringr::str_replace_all(nome_muni, \"-\", \" \"),\n  nome_muni = abjutils::rm_accent(nome_muni))\n\n\n\nApós arrumar a base, podemos unir com as funções do tipo join_*, do pacote dplyr (Sim, é possível usar as funções do tipo join_* com objetos de classe Simple Feature, porém use-os como o primeiro argumento ao usar a função):\n\n\napendice_c_geo <-\n  dplyr::full_join(municipios_sp_limpo, apendice_c_limpo) %>%\n  dplyr::left_join(ugrhis)\n\napendice_c_geo %>% nrow() # Confirmando se a nova base tem o número de municípios do estado.\n\n\n[1] 645\n\nAo unir as bases, temos colunas duplicadas ou desnecessárias, então é interessante removê-las. Após este procedimento, a base será filtrada para que apenas municípios que fazem parte das UGRHIs analisadas estejam na tibble gerada.\nAlém disso, o valor de porcentagem de atendimento de tratamento de esgoto é um valor de porcentagem em relação ao volume de esgoto coletado. Por exemplo, o município de Bertioga, segundo os dados da CETESB para 2018, apresenta uma porcentagem de coleta de apenas 34 % do esgoto gerado, e uma porcentagem de 100 % do esgoto tratado. Isso significa que 100 % do esgoto coletado é tratado, e não mostra a porcentagem de todo esgoto gerado que foi tratado. Para isso, criei também uma coluna (chamada porc_real_trat) onde é feito esse cálculo (utilizando a função mutate).\n\n\nsaneamento <- apendice_c_geo %>%\n  dplyr::select(-nome_muni,-municipio,-code_state) %>% # Remove colunas duplicadas\n  dplyr::filter(ugrhi %in% ugrhis$ugrhi) %>% # Filtra a coluna UGRHI. Apenas as UGRHIS que estão na tibble\n                                            # criada, permanecerão.\n  dplyr::mutate(porc_real_trat = atendimento_tratamento_porc * atendimento_coleta_porc / 100) # Cria uma nova\n# coluna, com o cálculo do número real de porcentagem de tratamento de esgoto.\n\n\n\nA base final que usaremos na análise contém dados de 171 municípios, que fazem parte de 6 UGRHIs diferentes. A soma da população urbana destes municípios é de 32.79 milhões de habitantes, o que corresponde à 75.1 % da população urbana do Estado de São Paulo (segundo os dados da base completa utilizada nessa análise).\nVisualizando os dados\nPara evitar duplicação de código, o código abaixo é referente ao estilo do mapa, que aplicarei em todos os mapas seguintes.\n\n\ntema_mapa <-\n  theme_bw() + # Escolhe o tema. Eu gosto do theme_bw() por ser bem simples/limpo\n  \n  # Os códigos abaixo são referentes à estética do tema,\n  # como o tamanho da fonte, direção do texto,\n  # linhas ao fundo, etc.\n  \n  theme(\n    axis.text.y = element_text(\n      angle = 90,\n      hjust = 0.5,\n      size = 8\n    ),\n    axis.text.x = element_text(size = 8),\n    axis.title.y = element_text(size = rel(0.8)),\n    axis.title.x = element_text(size = rel(0.8)),\n    panel.grid.major = element_line(\n      color = gray(0.9),\n      linetype = \"dashed\",\n      size = 0.1\n    ),\n    panel.background = element_rect(fill = \"white\") +\n      annotation_scale(location = \"br\", width_hint = 0.30)\n  )\n\n\n\nCom a função geom_sf(), é possível criar mapas utilizando o pacote ggplot2 e objetos de classe Simple Feature (sf). Assim podemos usar as nossas habilidades de criar gráficos lindos no ggplot2, e criar mapas também usando as funções que já conhecemos.\n\n\nclass(saneamento) # Função class() apresenta a classe do objeto. \n\n\n[1] \"sf\"         \"data.frame\"\n\nO mapa abaixo apresenta os municípios que fazem parte da análise, segundo a UGRHI, e a localização destes municípios no Estado de São Paulo. Podemos usar mais de uma camada geom_sf() no mesmo mapa, da mesma forma que fazemos com o ggplot2:\n\n\nsaneamento %>% # Base de dados usada\n  ggplot() + # Inicia o gráfico ggplot\n  geom_sf(data = apendice_c_geo,\n          # Camada do mapa da base completa (Estado SP)\n          alpha = .9,\n          color = NA) +\n  geom_sf(aes(fill = nome_ugrhi)) + # Camada do mapa da base saneamento\n  # Adiciona Título e Legendas\n  labs(fill = \"UGRHI\",\n       title = \"Municípios que fazem parte da análise, segundo a UGRHI\") +\n  # Adiciona o Norte Geográfico\n  annotation_north_arrow(\n    location = \"br\",\n    which_north = \"true\",\n    height = unit(1, \"cm\"),\n    width = unit(1, \"cm\"),\n    pad_x = unit(0.1, \"in\"),\n    pad_y = unit(0.1, \"in\"),\n    style = north_arrow_fancy_orienteering\n  ) +\n  ggspatial::annotation_scale() +\n  # Adiciona o tema criado anteriormente\n  tema_mapa \n\n\n\n\nO mapa abaixo apresenta a porcentagem de atendimento de coleta de esgoto, por município:\n\n\nsaneamento %>%\n  ggplot() +\n  geom_sf(aes(fill = atendimento_coleta_porc)) +\n  scale_fill_viridis_c(direction = -1, limits = c(0, 100)) + # Escala de cores\n  labs(fill = \"Porcentagem de \\natendimento de \\ncoleta de esgoto\",\n       title = \"Porcentagem de atendimento de coleta de esgoto, por município\",\n       subtitle = \"Dados da CETESB, para o ano de 2018.\") +\n  annotation_north_arrow(\n    location = \"br\",\n    which_north = \"true\",\n    height = unit(1, \"cm\"),\n    width = unit(1, \"cm\"),\n    pad_x = unit(0.1, \"in\"),\n    pad_y = unit(0.1, \"in\"),\n    style = north_arrow_fancy_orienteering\n  ) +\n  ggspatial::annotation_scale() +\n  tema_mapa \n\n\n\n\nO mapa abaixo apresenta a porcentagem de atendimento de tratamento de esgoto, considerando o total de esgoto coletado, por município:\n\n\nsaneamento %>%\n  ggplot() +\n  geom_sf(aes(fill = porc_real_trat)) +\n  scale_fill_viridis_c(direction = -1, limits = c(0, 100)) +\n  labs(fill = \"% de \\natendimento de \\ntratamento de esgoto \",\n       title = \"Porcentagem de atendimento de tratamento de esgoto, por município\",\n       subtitle = \"Calculado a partir de dados da CETESB, para o ano de 2018.\") +\n  annotation_north_arrow(\n    location = \"br\",\n    which_north = \"true\",\n    height = unit(1, \"cm\"),\n    width = unit(1, \"cm\"),\n    pad_x = unit(0.1, \"in\"),\n    pad_y = unit(0.1, \"in\"),\n    style = north_arrow_fancy_orienteering\n  ) +\n  ggspatial::annotation_scale() +\n  tema_mapa \n\n\n\n\nConclusão do post\nNeste post, mostrei um caminho reprodutível e realizado utilizando o R:\nCom o pacote pdftables, é possível converter tabelas que estão em arquivos PDF para arquivos CSV.\nCom o pacote geobr, é possível obter os arquivos shapefile para os mapas.\nCom as funções dos pacotes que fazem parte do tidyverse, diversas etapas da análise de dados são possíveis: ler os dados no R, limpeza de dados, manipulação dos dados, cruzamento de bases de dados, visualização, e outros.\nRecomendações para a base da CETESB\nAdicionar uma explicação sobre cada coluna da base disponibilizada.\nSeria melhor disponibilizar também o arquivo .CSV. Não disponibilizar PDFs digitalizados (Ex: relatório do ano de 2016).\nSeria útil adicionar, para os próximos relatórios, a coluna de código IBGE do município. Isso facilitaria o cruzamento com outras bases de dados.\nVerificar a grafia do nome dos municípios (está inconsistente com a lista de municípios da Assembléia Legislativa do Estado de São Paulo5): São Luiz do Paraitinga, Biritiba Mirim, Itaoca.\nInformações sobre a sessão do R e RStudio\nAs informações abaixo são interessantes para registrar a versão do R utilizada, versões de pacotes, entre outros.\n\n\nsessioninfo::session_info()\n\n\n─ Session info ─────────────────────────────────────────────────────\n setting  value                       \n version  R version 4.0.3 (2020-10-10)\n os       macOS Big Sur 10.16         \n system   x86_64, darwin17.0          \n ui       X11                         \n language (EN)                        \n collate  pt_BR.UTF-8                 \n ctype    pt_BR.UTF-8                 \n tz       America/Sao_Paulo           \n date     2021-03-07                  \n\n─ Packages ─────────────────────────────────────────────────────────\n package     * version    date       lib\n abjutils    * 0.3.1.9000 2021-01-29 [1]\n assertthat    0.2.1      2019-03-21 [1]\n backports     1.2.1      2020-12-09 [1]\n broom         0.7.5      2021-02-19 [1]\n bslib         0.2.4      2021-01-25 [1]\n cellranger    1.1.0      2016-07-27 [1]\n class         7.3-18     2021-01-24 [1]\n classInt      0.4-3      2020-04-07 [1]\n cli           2.3.1      2021-02-23 [1]\n colorspace    2.0-0      2020-11-11 [1]\n crayon        1.4.1      2021-02-08 [1]\n curl          4.3        2019-12-02 [1]\n DBI           1.1.1      2021-01-15 [1]\n dbplyr        2.1.0      2021-02-03 [1]\n digest        0.6.27     2020-10-24 [1]\n distill       1.2.2      2021-02-27 [1]\n downlit       0.2.1      2020-11-04 [1]\n dplyr       * 1.0.4      2021-02-02 [1]\n e1071         1.7-4      2020-10-14 [1]\n ellipsis      0.3.1      2020-05-15 [1]\n evaluate      0.14       2019-05-28 [1]\n fansi         0.4.2      2021-01-15 [1]\n farver        2.0.3      2020-01-16 [1]\n forcats     * 0.5.1      2021-01-27 [1]\n fs            1.5.0      2020-07-31 [1]\n generics      0.1.0      2020-10-31 [1]\n geobr       * 1.5-1      2021-02-06 [1]\n ggplot2     * 3.3.3      2020-12-30 [1]\n ggspatial   * 1.1.5      2021-01-04 [1]\n glue          1.4.2      2020-08-27 [1]\n gtable        0.3.0      2019-03-25 [1]\n haven         2.3.1      2020-06-01 [1]\n highr         0.8        2019-03-20 [1]\n hms           1.0.0      2021-01-13 [1]\n htmltools     0.5.1.9000 2021-02-27 [1]\n httr          1.4.2      2020-07-20 [1]\n jquerylib     0.1.3      2020-12-17 [1]\n jsonlite      1.7.2      2020-12-09 [1]\n KernSmooth    2.23-18    2020-10-29 [1]\n knitr       * 1.31       2021-01-27 [1]\n labeling      0.4.2      2020-10-20 [1]\n lifecycle     1.0.0      2021-02-15 [1]\n lubridate     1.7.10     2021-02-26 [1]\n magrittr    * 2.0.1      2020-11-17 [1]\n modelr        0.1.8      2020-05-19 [1]\n munsell       0.5.0      2018-06-12 [1]\n pdftables   * 0.1        2016-02-15 [1]\n pillar        1.5.0      2021-02-22 [1]\n pkgconfig     2.0.3      2019-09-22 [1]\n purrr       * 0.3.4      2020-04-17 [1]\n R6            2.5.0      2020-10-28 [1]\n Rcpp          1.0.6      2021-01-15 [1]\n readr       * 1.4.0      2020-10-05 [1]\n readxl        1.3.1      2019-03-13 [1]\n reprex        1.0.0      2021-01-27 [1]\n rlang         0.4.10     2020-12-30 [1]\n rmarkdown     2.7.2      2021-02-28 [1]\n rstudioapi    0.13       2020-11-12 [1]\n rvest         0.3.6      2020-07-25 [1]\n sass          0.3.1      2021-01-24 [1]\n scales        1.1.1      2020-05-11 [1]\n sessioninfo   1.1.1      2018-11-05 [1]\n sf          * 0.9-7      2021-01-06 [1]\n stringi       1.5.3      2020-09-09 [1]\n stringr     * 1.4.0      2019-02-10 [1]\n tibble      * 3.1.0      2021-02-25 [1]\n tidyr       * 1.1.2      2020-08-27 [1]\n tidyselect    1.1.0      2020-05-11 [1]\n tidyverse   * 1.3.0      2019-11-21 [1]\n units         0.6-7      2020-06-13 [1]\n utf8          1.1.4      2018-05-24 [1]\n vctrs         0.3.6      2020-12-17 [1]\n viridisLite   0.3.0      2018-02-01 [1]\n withr         2.4.1      2021-01-26 [1]\n xfun          0.21       2021-02-10 [1]\n xml2          1.3.2      2020-04-23 [1]\n yaml          2.2.1      2020-02-01 [1]\n source                            \n Github (abjur/abjutils@caa109c)   \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.3)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.3)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.3)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.1)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n Github (rstudio/distill@3c2a367)  \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.1)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n Github (rstudio/htmltools@ac43afe)\n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.3)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.3)                    \n CRAN (R 4.0.3)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.3)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n Github (rstudio/rmarkdown@f31844d)\n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.3)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.1)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n CRAN (R 4.0.2)                    \n\n[1] /Library/Frameworks/R.framework/Versions/4.0/Resources/library\n\nO projeto foi realizado com R (R Core Team 2020), e os pacotes: {abjutils} (Lente and Trecenti 2020), {dplyr} (Wickham et al. 2021), {geobr} (Pereira and Goncalves 2021), {ggplot2} (Wickham et al. 2020; Wickham 2016), {ggspatial} (Dunnington 2021), {knitr} (Xie 2021, 2015), {magrittr} (Bache and Wickham 2020), {pdftables} (Persson 2016), {readr} (Wickham and Hester 2020), {rmarkdown} (Allaire et al. 2021; Xie, Allaire, and Grolemund 2018), {sf} (Pebesma 2021, 2018), {stringr} (Wickham 2019), {tibble} (Müller and Wickham 2021).\nMuito obrigada!\nAo Professor Jonathan Phillips, pelo oferecimento da disciplina “FLS6397 - Introdução à Análise de Dados, Programação e Visualização para as Ciências Sociais”, por sua disponibilidade para tirar as dúvidas de todes, disponibilização de todo material da aula na internet de forma aberta e gratuita, e pelo esforço para que a disciplina fosse proveitosa mesmo considerando o contexto de pandemia.\nA Vanessa Escolano Maso, amiga, parceira na R-Ladies São Paulo e também na disciplina, pela companhia durante a disciplina e também por revisar e sugerir melhoras neste post.\nAo Maurício Vancine pela sua sugestão via twitter de utilizar a função ggspatial::annotation_scale() para adicionar uma barra de escala nos gráficos.\n\n\n\n\n\n\nAllaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2021. Rmarkdown: Dynamic Documents for r.\n\n\nBache, Stefan Milton, and Hadley Wickham. 2020. Magrittr: A Forward-Pipe Operator for r. https://CRAN.R-project.org/package=magrittr.\n\n\nDunnington, Dewey. 2021. Ggspatial: Spatial Data Framework for Ggplot2. https://CRAN.R-project.org/package=ggspatial.\n\n\nLente, Caio, and Julio Trecenti. 2020. Abjutils: Useful Tools for Jurimetrical Analysis Used by the Brazilian Jurimetrics Association. https://github.com/abjur/abjutils.\n\n\nMüller, Kirill, and Hadley Wickham. 2021. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble.\n\n\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\n———. 2021. Sf: Simple Features for r. https://CRAN.R-project.org/package=sf.\n\n\nPereira, Rafael H. M., and Caio Nogueira Goncalves. 2021. Geobr: Loads Shapefiles of Official Spatial Data Sets of Brazil. https://github.com/ipeaGIT/geobr.\n\n\nPersson, Eric. 2016. Pdftables: Programmatic Conversion of PDF Tables. https://CRAN.R-project.org/package=pdftables.\n\n\nR Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2019. Stringr: Simple, Consistent Wrappers for Common String Operations. https://CRAN.R-project.org/package=stringr.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2020. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2021. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Jim Hester. 2020. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.\n\n\n———. 2021. Knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown.\n\n\nhttps://cetesb.sp.gov.br/↩︎\nhttps://support.rstudio.com/hc/en-us/articles/200532197-Character-Encoding↩︎\nhttps://www.al.sp.gov.br/documentacao/municipios-paulistas/↩︎\nPlano Diretor de Aproveitamento dos Recursos Hídricos para a Macrometrópole Paulista - http://www.daee.sp.gov.br/↩︎\nhttps://www.al.sp.gov.br/documentacao/municipios-paulistas/↩︎\n",
    "preview": "posts/2020-07-27-criando-mapas-com-os-pacotes-tidyverse-e-geobr/criando-mapas-com-os-pacotes-tidyverse-e-geobr_files/figure-html5/mapa-tratamento-1.png",
    "last_modified": "2021-03-07T14:08:08-03:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-02-22-the-carpentries-como-fazer-o-treinamento-de-instrutora/",
    "title": "The Carpentries: Como fazer o treinamento de instrutora?",
    "description": "Neste post, vou contar um pouco sobre o que é a The Carpentries, como conheci este projeto, como foi o treinamento para me tornar uma instrutora, e quais desafios que percebi para o crescimento da comunidade no Brasil.",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2020-02-22",
    "categories": [
      "Ensino",
      "The Carpentries",
      "Portugues"
    ],
    "contents": "\nOlá a todes! Neste post, vou contar um pouco sobre o que é a The Carpentries, como conheci este projeto, como foi o treinamento para me tornar uma instrutora, e quais desafios que percebi para o crescimento da comunidade no Brasil.\nO que é a The Carpentries?\n\n\n\n\nLogo da The Carpentries. Fonte: The Carpentries\n\nA The Carpentries é uma comunidade global que desenvolve materiais e realiza workshops sobre habilidades de programação (principalmente ciência de dados). Os conteúdos dos workshops são desenvolvidos pela comunidade, através do GitHub. Esses workshops são realizados por instrutores(as) que recebem um treinamento e são certificados.\nLeia abaixo a missão e visão da The Carpentries:\n\nVisão: Nossa visão é ser a comunidade inclusiva líder em ensino de dados e habilidades de programação. Missão: A Carpentries desenvolve capacidade global em dados essenciais e habilidades computacionais para conduzir pesquisas eficientes, abertas e reproduzíveis. Treinamos e promovemos uma comunidade ativa, inclusiva e diversificada de alunos e instrutores que promove e modela a importância do software e dos dados na pesquisa. Colaboramos no desenvolvimento de lições abertas e entregamos essas lições usando práticas de ensino baseadas em evidências. Focamos nas pessoas que conduzem e apoiam pesquisas. Fonte: https://carpentries.org/about/\n\nUm ponto que acredito ser indispensável em qualquer comunidade é ter um código de conduta. Na The Carpentries, o código de conduta é continuamente discutido e aprimorado!\nA The Carpentries engloba 3 projetos: Data Carpentry, Software Carpentry e Library Carpentry. Cada projeto tem um foco, mas todos criam materiais de ensino e promovem workshops sobre R, Python, Git e muito mais.\nSegue abaixo uma lista de materiais sobre R disponíveis nos projetos:\nData Carpentry\nData Analysis and Visualization in R for Ecologists\nIntroduction to R for Geospatial Data\nIntroduction to Geospatial Raster and Vector Data with R\n\nSoftware Carpentry\nProgramming with R\nR for Reproducible Scientific Analysis\n\nLibrary Carpentry\nIntroduction to R\n\nOs materiais são desenvolvidos em inglês. Alguns materiais estão sendo traduzidos para espanhol, sendo uma iniciativa da comunidade da The Carpentries na América Latina. Infelizmente não estão disponíveis materiais em português, pois a comunidade brasileira da The Carpentries ainda é pequena, o que é possível de observar no mapa abaixo:\n\n\n\n\nMapa de instrutores(as) da Carpentries. Data: Fevereiro/2020 Fonte: Carpentries - Instructors Map.\n\nComo conheci a The Carpentries?\nAgora que já expliquei o que é a The Carpentries, vou falar um pouco sobre como eu conheci esse projeto.\nNo segundo semestre de 2018, quando estava começando a aprender R, os organizadores do “2018 CODATA-RDA School of Research Data Science” entraram em contato com as R-Ladies São Paulo para ministrar voluntariamente um dia e meio de aula de R em inglês. Mesmo com poucos meses de aprendizado, eu declarei interesse em participar. Na ocasião, a Haydee Svab e a Alissa Mune também participaram.\nEste curso ocorreu em dezembro de 2018, e utilizou o método da Carpentries de ensino, e também os materiais. O material utilizado foi o Programming with R, da Software Carpentry. Eu ministrei os conteúdos de Boas práticas (Best Practices for Writing R Code), e Relatórios dinâmicos com o knitr (Dynamic Reports with knitr), pois eram os conteúdos que eu tinha mais familiaridade. Foi uma oportunidade muito boa, onde eu aprendi bastante, e também conheci R-Ladies de outros capítulos da América Latina.\n\n\n\n\nR-Ladies no 2018 CODATA: Andrea Tapia - R-Ladies Rio de Janeiro, Natalia da Silva - R-Ladies Montevideo, Alissa Mune - R-Ladies São Paulo, Haydee Svab - R-Ladies São Paulo, eu, e Marcela Alfaro - R-Ladies San José.\n\nNessa ocasião, a Marce explicou o que é a Carpentries, disse que temos poucos instrutores(as) no Brasil, e me motivou a me inscrever no processo para fazer o treinamento para ser uma instrutora.\nTreinamento de instrutora\nNesta página é possível encontrar informações sobre o treinamento. Abaixo vou descrever como foi o meu processo de treinamento.\nRegistrando o interesse\nDepois do CODATA, eu demorei um pouco para começar. A primeira etapa foi preencher este formulário online registrando o interesse em realizar o treinamento. Eu preenchi em março de 2019.\nEmail de aceite\nNo início de abril de 2019, recebi o email em que indicava o link para me inscrever no treinamento. No site, são disponíveis diversas opções de datas e horários. Eu me inscrevi para realizar o treinamento em Julho/2019, pois o mesmo tem duração de 2 dias (online), e no primeiro semestre eu estava ocupada com as disciplinas da pós.\nTreinamento\nO treinamento foi realizado em Julho/2019 através do Zoom (online), com duração de 2 dias. É importante destacar que o treinamento foi inteiramente realizado em inglês. Nesta página é possível ver os conteúdos abordados. O curso foca em boas práticas para o ensino, e foi riquíssimo, contando com atividades práticas. Uma das minhas atividades favoritas foi em grupo: cada pessoa do grupo deveria compartilhar a tela do computador e apresentar uma curta aula, e os participantes do grupo fornecem feedbacks positivos e negativos.\nDepois de completar o treinamento, existem 3 etapas para concluir o checkout process: participar de uma reunião da comunidade (community discussion), fazer uma contribuição em algum material da Carpentries, e apresentar uma aula de 5 minutos codando ao vivo (live coding). Essas etapas devem ser realizadas em até 3 meses após participar do treinamento online.\nCommunity discussion\nPara participar da community discussion, existe um documento com diversas opções de horários e datas. Eu coloquei meu nome em uma opção de data que eu poderia participar. A reunião é online e dura 1 hora, e participaram pessoas que estão no treinamento, e também instrutores(as) experientes.\nFoi muito interessante ouvir as pessoas contando quais foram os aprendizados que tiveram nos workshops oferecidos. Algo que eu achei muito interessante são os relatos do que errado nos workshops, pois assim podemos pensar em formas de prevenir estes problemas em workshops futuros!\nContribuindo com os materiais\nComo disse anteriormente, todos os materiais da Carpentries são desenvolvidos e aprimorados pela comunidade, através do GitHub. Então parte do treinamento é realizar uma contribuição, seja com um pull request, respondendo uma issue ou dando alguma sugestão/feedback.\nEu estava estudando uma das lições da Data Carpentry para me preparar para a etapa de live coding. Em Agosto/2019, fiz uma contribuição respondendo uma issue com uma sugestão relacionado à lição Data Analysis and Visualization in R for Ecologists.\nLive Coding\nEssa foi a última etapa, que realizei em Setembro/2019! A dinâmica é a seguinte: deve-se escolhar uma lição da Carpentries (eu escolhi essa), e estudar o material.\nDepois de estudar o conteúdo da lição Data Analysis and Visualization in R for Ecologists, adicionei meu nome e a lição escolhida no documento com as datas disponíveis para o Live Coding.\nA avaliação é realizada em uma ligação no Zoom, com outras pessoas que estão em treinamento e uma pessoa avaliadora. A pessoa avaliadora então escolhe em qual tópico do curso a aula com live coding deve começar (por isso é necessário estudar todo o material escolhido!).\nEntão eu compartilhei a minha tela com todos(as), abri o RStudio, e dei uma aula de 5 minutos em inglês, com live coding, utilizando as práticas que aprendemos no treinamento. Depois de apresentar a aula, é necessário fazer um feedback de si mesmo (positivo e negativo). O feedback que eu fiz para mim mesma é que senti que eu parava para pensar no termo em inglês, e isso prejudicava o ritmo da aula. A pessoa que estava avaliando me tranquilizou e disse que isso não afetou a qualidade da aula. As outras pessoas que estavam em treinamento elaboraram feedbacks, o que me deixou super feliz, já que recebi feedbacks bem legais (um exemplo foi falarem que a minha voz e jeito de falar é animada e deixou as pessoas interessadas no conteúdo apresentado).\nDepois de apresentar e receber os feedbacks, também assisti as aulas de outras pessoas em treinamento, e dei feedbacks.\nConcluindo o Checkout Process\nDepois de cumprir todas essas etapas e informar por email (por exemplo, o link da issue que contribuí), esperei um tempo e verifiquei neste site que já havia cumprido os requisitos. Preenchi os dados que faltavam, e em pouco tempo o meu nome apareceu na lista de instrutores(as): (é preciso utilizar o ctrl+F, pois são muitas pessoas!)\n\n\n\n\nPrint screen da página de instrutores(as) da Carpentries. Fonte: Carpentries - Our Instructors.\n\nDesde então, posso organizar e dar aula em Workshops da Carpentries. Eu e o Raniere Silva estamos em contato com ideias de organizar workshops neste ano!\nEu aprendi bastante neste treinamento, o que possibilitou ter um olhar crítico sobre as aulas e materiais que eu (e outras pessoas também) ofereço. Desenvolver a habilidade de fornecer feedbacks construtivos, e praticar live coding foram conteúdos que também gostei muito no treinamento da Carpentries.\nDesafios para a comunidade Carpentries no Brasil\nDentre os desafios que percebi, o que mais chama a atenção é que o treinamento para se tornar uma pessoa instrutora é totalmente em inglês. Isso acaba dificultando a participação de muitas pessoas que não falam inglês. Além disso, existem poucos instrutores(as) certificados no Brasil. Consequentemente o material dos workshops estão em inglês, pois ainda não foram traduzidos.\nNos países da América Latina que falam espanhol, as pessoas instrutoras trabalham em equipe para traduzir os materiais dos workshops, e também já ofereceram o treinamento para instrutores(as) em espanhol.\nPortanto, se queremos ter materiais e workshops em português, é essencial que a comunidade da Carpentries cresça no Brasil!\n\n\n\nEscrevi este post com o objetivo de deixar mais claro como foi este processo. Estou à disposição em caso de outras dúvidas:  milz.bea@gmail.com e  telegram.\nAgradecimentos:\nGostaria de agradecer algumas pessoas que fizeram parte do treinamento e avaliação, ou de alguma forma contribuíram com este processo: Marcela Alfaro, Sarah Stevens, Maneesha Sane, François Michonneau e Raniere Silva.\n\n\n\n",
    "preview": "posts/2020-02-22-the-carpentries-como-fazer-o-treinamento-de-instrutora/mapa.jpg",
    "last_modified": "2021-02-28T22:44:37-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-08-31-um-ano-aprendendo-r/",
    "title": "Um ano aprendendo R!",
    "description": "Um relato deste um ano aprendendo R!",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2019-08-31",
    "categories": [
      "Portugues",
      "R-Ladies"
    ],
    "contents": "\nEsse post é uma continuação deste outro: Meio ano de aprendizagem de R!, onde relatei um pouco sobre os primeiros seis meses de aprendizagem em programação, principalmente na linguagem R.\nComo dito no post citado, eu começei a aprender R e programação em agosto de 2018. Ou seja, neste mês completo um ano de aprendizagem! 🎂 🎈 Foi um ano muito rico de experiências, onde conheci muitas pessoas queridas e aprendi muito também!\nR-Ladies São Paulo 💜\nConhecer a organização R-Ladies São Paulo foi uma das melhores coisas que já me aconteceu, e ter a oportunidade de contribuir com a organização dos eventos é algo que faço com muita alegria. Na R-Ladies, sinto que é um espaço muito acolhedor e seguro para aprender sobre R, compartilhar conhecimento, tirar dúvidas, fazer amizades, e muito mais.\nNeste mês de agosto, também foi o aniversário de 1 ano da R-Ladies São Paulo, e a apresentação feita no evento está disponível neste link. Foi um evento muito querido! E abaixo segue uma foto de como foi:\n\n\n\nE uma thread no twitter contando mais detalhes sobre como foi o evento:\n\n\n\nSábado passado aconteceu o #meetup de aniversário de 1 ano da #RLadies São Paulo! O evento aconteceu lá na @thoughtworksbr , fomos super bem recebidas pela Chris, agradecemos muito pelo espaço e coffe break! Segue algumas fotos: #rstats #rstatsbr pic.twitter.com/FfW8Et1FVx\n\n— R-Ladies São Paulo (@RLadiesSaoPaulo) August 24, 2019\n\n\nAprendizado\nNeste primeiro ano, fiz diversos cursos sobre R, sendo alguns online e outros presenciais, destacando os seguintes:\nPresencial, Setembro/2018 - Introdução à Programação em R, da Curso-R - Neste curso, tive um contato maior com o pacote tidyverse. Foi um divisor de águas para mim, e saí muito empolgada para aprender mais! Agradeço a Curso-R pela bolsa recebida!\nPresencial, Maio/2019 - Building web applications in R using Shiny, do Dean Atalli - Foi um workshop sobre como criar aplicações Web utilizando o pacote Shiny. Teve muitas atividades práticas, e aprendi bastante! Fiquei muito animada para aprender mais…\nPresencial, Junho/2019 - Dashboards com R, da Curso-R - Foi um curso bem prático, focado em criar dashboards usando RMarkdown e também Shiny. Na última aula, os professores também citaram os pacotes mais recentes relacionados ao desenvolvimento de Shiny Apps!\nOnline, 2019 - Coursera - Programa de cursos integrados Ciência de Dados (02/10) - Atualmente estou fazendo esse programa de cursos oferecidos pela Johns Hopkins University. Já completei dois cursos: As Ferramentas do Cientista de Dados e Linguagem R. Atualmente estou finalizando o curso de Obtenção e Limpeza de Dados, e sinceramente já deveria ter completado, porém sinto que meu ritmo é mais devagar mesmo em aulas online. Aulas presenciais me deixam mais empolgada! 😃\nPara os próximos meses espero conseguir evoluir no programa de Ciência de dados do Coursera!\nEventos\nIV SER UFF\nO SER - International Seminar on Statistics with R, é um evento realizado na Universidade Federal Fluminense, em Niterói - RJ. Essa foi a primeira conferência que participo sobre R, e aconteceu em maio de 2019.\nConheci muitas pessoas legais nesse evento: R-Ladies de outros capítulos do Brasil, os organizadores do evento, algumas pessoas do grupo do telegram R Brasil e muito mais.\nEu e a Haydee Svab (co-organizadora do R-Ladies São Paulo) submetemos um mini-curso no evento, e ele foi aceito e oferecido junto ao evento do R-Ladies Niterói. O tema do mini-curso foi: Comunicando seus resultados: Criando apresentações com R. Segue abaixo uma foto que tiramos com R-Ladies de outros capítulos, que participaram do mini-curso:\n\n\n\nOutra participação no evento foi na apresentação de um pôster, que foi escrito por quatro co-organizadoras do R-Ladies São Paulo: eu, Bruna Garbes, Bruna Wundervald e Haydee Svab. O texto do pôster está disponível online, e tem o seguinte título: Ensino de R através da Comunidade R-Ladies - Capítulo São Paulo. O pôster em formato PDF está disponível neste link.\nuseR!2019\nA useR!2019 foi a segunda conferência que participei de R, e aconteceu em julho de 2019, em Toulouse, na França. Não vou me prolongar pois pretendo fazer um post só sobre o evento (sim, estou atrasada 😞). Eu e a Angélica Custódio recebemos bolsas de diversidade para participar do evento. Nós escrevemos um post juntas, relatando a experiência de participar do tidyverse developer day.\nNa foto a seguir, está o grupo de brasileiros que participaram do evento: Laurie Baker (que não é Brasileira, mas andou conosco no evento), Angélica Custódio, Julio Trecenti, eu, Daniel Falbel e o William Amorim. O Prof. Elias Krainski também participou, porém não está na foto.\n\n\n\nAliás, o Julio Trecenti escreveu um post relatando a experiência dele de participar deste evento: Minha experiência na useR!2019.\nEu e a Bruna Wundervald escrevemos um resumo para Lightning Talk (uma palestra de 5 minutos), que foi aceito. Fiquei nervosa para apresentar, já que era a primeira vez apresentando em inglês, fora do Brasil, e para um público tão legal! A apresentação está disponível neste link, e também está disponível no youtube:\n\n\n\n\nE eu ainda fiz amizade com uma pessoa muito querida e maravilhosa: A Angélica Custódio! 💜 Uma foto nossa turistando em Toulouse:\n\n\n\nCompartilhando conhecimento\nApresentações me deixam nervosa, e isso não é segredo para ninguém.. Acabo falando super rápido, e depois fico me sentindo mal por isso.\n\n\n\nQuero melhorar nessa questão (e se alguém tiver dicas, me enviem por favor), mas tento não deixar o receio de falar muito rápido me impedir de tentar compartilhar o que já aprendi.\nO que aprendi nesse 1 ano de R é devido à comunidade. Eu ainda preciso e quero aprendender muitas coisas ainda, mas acho válido compartilhar o que eu aprendi até então, e acredito que é uma forma de retribuir para a comunidade um pouco do que tanto que recebi até agora.\nAs apresentações que fiz geralmente deixo disponível nessa página, para que todos consigam consultar.\nPróximos passos\nEm setembro, participarei da Latin-R - Conferencia Latinoamericana sobre Uso de R en Investigación + Desarrollo, pois fui selecionada para receber um bolsa de diversidade. Estou muito animada para conhecer mais pessoas da comunidade de R Latinoamericana.\nNo projeto temático de pesquisa que faço parte (Governança ambiental da Macrometrópole Paulista face à variabilidade climática), existem pessoas que já programam em R, e também pessoas que tem interesse em aprender.\nRecentemente, eu e mais duas pessoas que já programam em R (a Rosana Laura e o Diego Braga, ambos pós-graduandos em Planejamento e Gestão do Território na UFABC) começamos a organizar um grupo de estudos para que a equipe do projeto possa compartilhar conhecimentos sobre R, considerando que os temas de pesquisa são bem diversos e utilizam metodologias diferentes também. O primeiro encontro do grupo de estudos está programado para setembro de 2019!\nE é isso, espero continuar aprendendo muito sobre R, e compartilhando também. 💜\n\n\n\n\n\n\n",
    "preview": "https://beatrizmilz.com/img/1anorladies.jpg",
    "last_modified": "2021-02-28T22:44:27-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-08-21-desenvolvendo-meu-primeiro-shiny-app/",
    "title": "Desenvolvendo meu primeiro Shiny App",
    "description": "O objetivo deste post é compartilhar um pouco sobre a minha experiência no desenvolvimento do meu primeiro Shiny App.",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2019-08-21",
    "categories": [
      "Shiny",
      "Portugues"
    ],
    "contents": "\nAprendendo sobre o pacote Shiny\nO objetivo deste post é compartilhar um pouco sobre a minha experiência no desenvolvimento do meu primeiro Shiny App. O Shiny é um pacote do R utilizado para desenvolver web apps interativos. Exemplos de Shiny Apps estão disponíveis nessa página.\n\n\n\nFigure 1: Hex Logo do pacote Shiny\n\n\n\nQuando conheci o Shiny, fiquei encantada. Parecia uma ótima forma de comunicar os dados interativamente, com as pessoas que não necessariamente conhecem o R. Então no começo do ano de 2019 coloquei como meta: gostaria de começar a aprender como usar esse pacote.\nNo evento IV SER - IV Internacional Seminar on Statistics with R tive a oportunidade de assistir um workshop sobre shiny, oferecido pelo Dean Attali, que é consultor Shiny e uma referência no tema! Foi um ótimo workshop e fiquei bem feliz de conseguir acompanhar os exercícios.\nQuando voltei do evento, não queria parar de estudar e praticar o que comecei a aprender. Então recebi um email da Curso-R comunicando que havia turma aberta para o curso de Dashboards com R. Eu já havia participado de dois cursos da Curso-R (Introdução à programação em R e Webscrapping em R), e sabia que os cursos oferecidos eram muito bons. Então fiz a inscrição, e no mês de junho foram três sábados de estudos e bastante prática com Shiny! Recomendo muito o curso, os professores são muito bons.\nDesenvolvimento\nEsse post é uma continuação do post Ferramenta para Pesquisa de Periódicos, onde descrevi o Shiny App que criei, mas agora o foco é relatar um pouco o processo de desenvolvimento. Todos os códigos estão disponíveis neste repositório no Github.\n\n\n\nExemplo de uso - Página para Pesquisa de Periódicos\nOs dados foram obtidos no website da CAPES. A página permite o download de uma tabela contendo o ISSN, título do periódico, área de avaliação e a nota na respectiva área. Utilizei os dados da avaliação mais recente disponível em junho/2019: 2013-2016.\nA IDE que utilizei foi o RStudio, e os pacotes que usados foram:\nshiny - usado para criar a plataforma interativa;\nshinydashboard - permite fazer dashboards com o shiny. Com a ajuda de CSS, consegui personalizar as cores do meu dashboard;\nshinyWidgets - oferece inputs diferentes, utilizei o sliderTextInput().\nDT - esse pacote permite usar tabelas no R utilizando a biblioteca JavaScript DataTables.\ntidyverse - readr, dplyr, purrr e stringr - usei os pacotes que fazem parte do tidyverse em diversas etapas do processo, como ler a base de dados, filtrar, manipular, alterar, entre outros;\njanitor - usei a função janitor::clean_names() , que permite alterar nome de todas as colunas da base de dados, deixando-as no padrão snake_case.\nO deploy foi feito gratuitamente no shinyapps.io, diretamente do RStudio!\nA maior dificuldade que tive com esse dashboard foi o filtro que gera a tabela. Inicialmente, ele não resultava o que eu precisava… eu fiquei cerca de duas semanas com esse problema, até que levei para os professores da Curso-R na última aula. Agradeço imensamente ao Julio Trecenti e ao William Amorim, que solucionaram o problema! Sem a ajuda que recebi, esse Shiny App ainda estaria apenas no meu computador…\nPor outro lado, é muito gratificante ver tudo funcionando, ter ideias e conseguir implementá-las! Mostrei para algumas pessoas, que deram feedbacks sobre as dificuldades que tiveram ao utilizar a página. Isso foi muito importante também para aprimorar o Shiny App.\nPróximas etapas\nAlgumas pessoas sugeriram algumas melhorias que dependem de dados que não estão nessa base disponibilizada pela CAPES. Considerando que a nova avaliação do Qualis será disponibilizada nos próximos meses, e existem notícias de que essa avaliação será unificada (cada periódico terá apenas uma nota geral, e não uma nota por área de avaliação), achei melhor esperar os resultados do novo Qualis para então pensar nas possibilidades de atualização e melhoria deste Shiny App.\nSobre o aprendizado de Shiny, eu gostaria de praticar mais. Já tenho uma ideia para um próximo Shiny App, agora o que falta é ter tempo para isso. Além disso, gostaria de aprender a utilizar o pacote golem, e a deixar meus Apps disponíveis em outras plataformas, como por exemplo na AWS ou Digital Ocean.\n\n\n\n",
    "preview": "https://raw.githubusercontent.com/rstudio/hex-stickers/master/thumbs/shiny.png",
    "last_modified": "2021-02-28T22:44:19-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-06-24-compartilhando-contedo-utilizando-r/",
    "title": "Compartilhando conteúdo",
    "description": "Como compartilhar conteúdo sobre R, utilizando R?",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2019-06-24",
    "categories": [
      "R-Ladies",
      "R Markdown",
      "Portugues"
    ],
    "contents": "\nAtualização da página\nNo último final de semana, utilizei algumas horas para reformular essa página. Eu utilizava o tema Academic, porém queria algo mais simples, então mudei para o Lithium. Além disso, também habilitei os comentários com o Disqus, habilitei o Google Analytics e também resolvi testar o Netlify (que aliás achei incrível).\nDurante esse processo, algumas dificuldades apareceram… Também lembrei da primeira vez que criei uma página com o blogdown, onde graças à muitos conteúdos online eu consegui colocar no ar depois de várias mensagens de erro.\n\n\n\nConteúdos online\nOs conteúdos online, que muitas pessoas disponibilizaram através de posts em blog, livros, documentação, dúvidas no Stackoverflow, me ajudaram muito a conseguir entender como funcionava o processo de criar uma página com o blogdown. Esses conteúdos foram essenciais também para entender como deixar esse site disponível online utilizando o Github (lembrando que a minha formação é em Gestão Ambiental). Porém a maior parte desse conteúdo estava disponibilizado em inglês: foram poucos os materiais que encontrei em português.\n\n\n\nLembrei também da conversa que tive rapidamente no mês passado com a Julia, co-organizadora do R-Ladies Niterói, onde disse que seria interessante que ela disponibilizasse online as palestras que ela já fez, para que outras pessoas consigam consultar e aprender com o conteúdo.\nSe você está em dúvida se deve compartilhar conteúdo na internet, eu indico a palestra (em inglês) do David Robinson na rstudio::conf 2019, chamada “The unreasonable effectiveness of public work”.\nAs formas de compartilhar conteúdo apontadas por David são: escrever um post em um blog, escrever um tweet, contribuir com projetos open source, dar palestras, gravar a tela enquanto faz alguma análise de dados e disponibilizar o vídeo, e escrever um livro sobre o assunto.\nNessa palestra, David diz que se você der a mesma dica/conselho três vezes, escreva um post em um blog, assim muitas pessoas conseguem acessar esse conteúdo.\n\n\n\nCompartilhando conteúdo sobre R e utilizando R\nPor isso, pretendo fazer alguns posts em português com algumas dicas sobre como compartilhar conteúdo na internet, utilizando R. Não é segredo que eu sou fã dos pacotes criados pelo Yihui Xie, então os temas que pretendo abordar são:\nCriar seu currículo com R, usando o pacote pagedown;\nCriar uma página/blog com R, usando o pacote blogdown.\nCriar apresentações com R, usando o pacote xaringan - lembrando que existe uma apresentação sobre esse assunto disponível aqui. O Bruno Lucian se interessou em compartilhar esse conteúdo no blog Dados Aleatórios, então quando estiver disponível eu colocarei o link para o post aqui também.\nGit e Github\nPara o compartilhar conteúdo, é interessante também utilizar git e Github. Mas considerando que nesse tema já existe bastante conteúdo em português, por enquanto vou focar nas ferramentas com R, que tem menos conteúdo disponível nessa língua.\nO post do William Oliveira, chamado Plano para estudar Git e GitHub enquanto aprende programação, me ajudou bastante a entender como começar a usar o git. Nesse post ele utiliza o terminal, e para algumas pessoas que estão iniciando essa abordagem pode ser um pouco intimidadora.\nOutra opção para quem está iniciando é utilizar o Github Desktop. Acredito que é uma interface amigável para quem está aprendendo como funciona o git.\nAté logo!\nPretendo postar sobre esses conteúdos logo logo. Enquanto isso, estou aberta à sugestões. Existem outras formas que vocês usam para divulgar conteúdo utilizando R? Existe alguma que você conheça e gostaria de aprender mais? Existem dificuldades? Se sim, quais?\n\n\n\n\n\n\n",
    "preview": "https://media.giphy.com/media/dNgK7Ws7y176U/giphy.gif",
    "last_modified": "2021-02-28T22:44:12-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-01-29-meio-ano-r/",
    "title": "Meio ano de aprendizagem de R!",
    "description": "Neste texto, gostaria de compartilhar um pouco sobre os primeiros seis meses de aprendizagem em programação, principalmente na linguagem R.",
    "author": [
      {
        "name": "Beatriz Milz",
        "url": "https://beatrizmilz.com"
      }
    ],
    "date": "2019-01-29",
    "categories": [
      "Comunidades",
      "R-Ladies",
      "Portugues"
    ],
    "contents": "\nNeste texto, gostaria de compartilhar um pouco sobre os primeiros seis meses de aprendizagem em programação, principalmente na linguagem R, e também agradecer a todas que participaram deste aprendizado.\nComo surgiu o interesse em aprender R?\nMeu nome é Beatriz, e a minha graduação foi em Gestão Ambiental. Porém, quando estava no mestrado, precisava utilizar a linguagem R para realizar análises estatísticas com os dados que coletei. Nunca me imaginei aprendendo a programar, e até tentei utilizar sozinha o R em 2017 (sem o RStudio), mas tive muita dificuldade. Então outra pessoa me ajudou com essas análises.\nDepois que conclui o mestrado, no segundo semestre de 2018, passei alguns meses me preparando e participando do processo seletivo do doutorado, e pensei que seria uma boa época para tentar aprender a “mexer com o R”. Eu queria conseguir fazer minhas próprias análises estatísticas sozinha! Perguntei para uma amiga, a Ana Lu, e ela me deu algumas dicas.\nR-Ladies\nEu e a Ana ficamos sabendo que iria acontecer o primeiro encontro do R-Ladies de São Paulo, que é uma organização que promove a diversidade de gênero na comunidade da linguagem R. Fiquei super animada, porém como não sabia naaaada ainda, eu corri e fiz o curso introdutório de R, a tempo de participar do meetup. Eu e a Ana Lu participamos deste encontro e conhecemos outras mulheres que programam ou estavam interessadas em aprender a programar em R.\nPrimeiro Meetup do R-Ladies em São Paulo:\n\n\n\nO primeiro meetup do R-Ladies foi muito especial para mim. Eu sabia tão pouco, e me senti em um ambiente super seguro e confortável para fazer as perguntas que tinha.O R-Ladies desde o começo foi um grupo onde me sentia confortável, segura, e havia uma troca muito grande de conhecimento. Considero que muito do que já aprendi sobre R eu quero agradecer à comunidade R-Ladies e todas as participantes do grupo de São Paulo. Então desde outubro de 2018 venho auxiliado na organização dos encontros, o que tem sido uma experiência super interessante, além de ser uma forma de retribuir o que eu tenho recebido!\nCursos\nDe agosto para cá tive a oportunidade de fazer outros cursos, porém o que considero um “divisor de águas” na minha aprendizagem sobre R foi o de Introdução à Programação em R, da Curso-R, devido a uma bolsa de diversidade de gênero que recebi e agradeço MUITO por essa oportunidade. Agradeço também a Maria pela companhia! Neste curso, além de aprender bastante e fazer miillllll perguntass (e agradeço os professores por também oferecerem um ambiente onde me sentisse confortável de perguntar tudo tudo tudo que tinha dúvida ou curiosidade), eu também saí de lá super empolgada em aprender mais sobre R.\nAtualmente estou me dedicando em realizar cursos online, pois em novembro fui contemplada com 3 meses de acesso através de uma bolsa de estudos para mulheres e minorias de gênero.\nEventos\nAlém dos cursos, alguns eventos também foram uma ótima oportunidade para aprender mais sobre o R e programação. A 13a aMostra Estatística que aconteceu no IME/USP foi um evento muito interessante onde tive a oportunidade de participar de 3 mini-cursos oferecidos pela Curso-R: Exploratory Data Analisys, Shiny e Rmarkdown. Agradeço a organização deste evento por oferecer um conteúdo tão legal e gratuito!\nEm novembro também fui contemplada com uma bolsa para jovens comunicadores e tive a oportunidade de participar do evento Coda BR. Eu fiquei tão feliz de poder participar deste evento, que mal tenho palavras para explicar como foi especial. Apesar de ter assistido conteúdo sobre R, o CODA BR foi muito além de programação: conheci mais sobre jornalismo de dados, tive a oportunidade de assistir palestras de especialistas nacionais e internacionais, conhecer pessoas que já admirava (a emoção de conhecer o Turicas, que eu admirava e conhecia através de podcasts e do trabalho no Brasil.IO), e principalmente conhecer muitas pessoas interessantes que depois se tornaram muito queridas para mim e que também fazem parte desta jornada.\nEnsinando R?\nTambém tive a oportunidade de ensinar outras pessoas sobre R. Acredito que, mesmo que ainda não sejamos experts, podemos compartilhar o que aprendemos com outras pessoas que também estão nessa caminhada. Além disso, descobri que ensinar outras pessoas é uma ótima forma de aprender mais também, principalmente pois quando preparo uma apresentação, eu pesquiso bastante e acabo aprendendo coisas novas (e tento sempre colocar as apresentações neste site para facilitar que outras pessoas tenham acesso).\nR-Ladies no CODATA, em São Paulo:\n\n\n\nConclusão\nAinda tenho muito para aprender sobre R. Ainda tenho muita dificuldade em estatística (mas descobri que tenho mais facilidade em outras tarefas que fazemos com R!). Espero aprender muito ainda, e compartilhar muito conhecimento também. Desejo contribuir para que a comunidade R-Ladies cresça, e retribuir, mesmo que apenas parcialmente, tudo o que recebi neste tempo e de alguma forma me ajudou nesta trajetória.\nGratidão à todos que contribuíram de alguma forma nessa caminhada em programação!\nE para fechar o post, coloco uma foto de recordação que significa muito para mim e simboliza a minha evolução neste meio ano.\nEu e a camiseta que recebi por ter participado da Hacktoberfest de 2018:\n\n\n\n\n\n\n",
    "preview": "https://beatrizmilz.com/img/rladies-1-meetup.jpeg",
    "last_modified": "2021-02-28T22:44:08-03:00",
    "input_file": {}
  }
]
